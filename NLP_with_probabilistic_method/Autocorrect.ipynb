{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "iOoLFVCu55JL"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Read from text file and create a corpous\n",
        "def process_data(text_file) :\n",
        "  words = []\n",
        "  with open(text_file) as f :\n",
        "    text_data = f.read()\n",
        "    text_data = text_data.lower()\n",
        "    words = re.findall('\\w+', text_data)\n",
        "  return words"
      ],
      "metadata": {
        "id": "PB_XPmYq6SXf"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT MODIFY THIS CELL\n",
        "word_l = process_data('shakespeare.txt')\n",
        "vocab = set(word_l)  # this will be your new vocabulary\n",
        "print(f\"The first ten words in the text are: \\n{word_l[0:10]}\")\n",
        "print(f\"There are {len(vocab)} unique words in the vocabulary.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bp3m0gLT8aGN",
        "outputId": "7cf12924-ddd0-4ea2-dddf-ffb2ae09f4b7"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first ten words in the text are: \n",
            "['o', 'for', 'a', 'muse', 'of', 'fire', 'that', 'would', 'ascend', 'the']\n",
            "There are 6116 unique words in the vocabulary.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_count(word_l) :\n",
        "  word_count_dict = {}\n",
        "  word_count_dict = Counter(word_l)\n",
        "  return word_count_dict"
      ],
      "metadata": {
        "id": "5-p1fg4J8z0H"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_count_dict = get_count(word_l)\n",
        "print(\"Length of the word count dictonary is  \",len(word_count_dict))\n",
        "print(\"\\nCount of first 10 words in vocabulary :\\n\")\n",
        "for word in word_l[0:10] :\n",
        "  print(f\"{word} : \",word_count_dict[word])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkQhJ4AW96uC",
        "outputId": "abf8493b-f9d0-404a-99bd-fbfc94c903cc"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of the word count dictonary is   6116\n",
            "\n",
            "Count of first 10 words in vocabulary :\n",
            "\n",
            "o :  157\n",
            "for :  474\n",
            "a :  757\n",
            "muse :  18\n",
            "of :  1094\n",
            "fire :  22\n",
            "that :  785\n",
            "would :  138\n",
            "ascend :  1\n",
            "the :  1525\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_count_dict['so']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fl_H_oLgvTH",
        "outputId": "79107ad1-81a0-4142-b5af-f85c4ae8dbe4"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "352"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#defined probability distribution on the vcabulary for each words\n",
        "\n",
        "def get_probs(word_count_dict) :\n",
        "  word_prob = {}\n",
        "  m = sum(word_count_dict.values())\n",
        "  for word in word_count_dict.keys() :\n",
        "    word_prob[word] = word_count_dict[word]/m\n",
        "  return word_prob"
      ],
      "metadata": {
        "id": "TwqbdPoK-RXE"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_prob_dict = get_probs(word_count_dict)\n",
        "print(\"\\nCount of first 10 words in vocabulary :\\n\")\n",
        "for word in word_l[0:10] :\n",
        "  print(f\"{word} : \",word_prob_dict[word])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L48t_v6iAmFj",
        "outputId": "f1fa453c-4b09-459a-8130-9eeca723d262"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Count of first 10 words in vocabulary :\n",
            "\n",
            "o :  0.0029283396127877045\n",
            "for :  0.008840974372365426\n",
            "a :  0.01411944641325027\n",
            "muse :  0.000335733204013877\n",
            "of :  0.020405118066176745\n",
            "fire :  0.0004103405826836274\n",
            "that :  0.014641698063938523\n",
            "would :  0.0025739545641063903\n",
            "ascend :  1.865184466743761e-05\n",
            "the :  0.028444063117842356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_prob_dict['so']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2gLn3QphAb4",
        "outputId": "533f8c1f-b19f-4a99-f0ac-5f6d29328c0e"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.006565449322938038"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Length of the probability dictonary is   \",len(word_prob_dict))\n",
        "print(word_prob_dict['thee'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NN1ImVK2BMHK",
        "outputId": "4164f2bc-2b2b-4dcb-dcdb-49a0dd8cf10c"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of the probability dictonary is    6116\n",
            "0.004476442720185026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#String manipulation"
      ],
      "metadata": {
        "id": "KhYxklAb8ygA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#delete operation\n",
        "def delete_letter(word,verbose = False) :\n",
        "  delete_l = []\n",
        "  split_l = []\n",
        "  for c in range(len(word)) :\n",
        "    split_l.append((word[:c], word[c:]))\n",
        "  for a,b in split_l :\n",
        "    delete_l.append(a+b[1:])\n",
        "\n",
        "  if verbose: print(f\"input word {word}, \\nsplit_l = {split_l}, \\ndelete_l = {delete_l}\")\n",
        "  return delete_l\n",
        "\n",
        "#example\n",
        "delete_letter(\"Mrinmoy\",True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "of2fVsmS8yPg",
        "outputId": "a6fabac6-72a3-4765-8def-2348d5cd95aa"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input word Mrinmoy, \n",
            "split_l = [('', 'Mrinmoy'), ('M', 'rinmoy'), ('Mr', 'inmoy'), ('Mri', 'nmoy'), ('Mrin', 'moy'), ('Mrinm', 'oy'), ('Mrinmo', 'y')], \n",
            "delete_l = ['rinmoy', 'Minmoy', 'Mrnmoy', 'Mrimoy', 'Mrinoy', 'Mrinmy', 'Mrinmo']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rinmoy', 'Minmoy', 'Mrnmoy', 'Mrimoy', 'Mrinoy', 'Mrinmy', 'Mrinmo']"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Switch_l\n",
        "\n",
        "def switch_letter(word,verbose = False) :\n",
        "  split_l = []\n",
        "  switch_l = []\n",
        "  for c in range(len(word)) :\n",
        "    split_l.append((word[:c], word[c:]))\n",
        "  switch_l = [a + b[1] + b[0] + b[2:] for a,b in split_l if len(b) >= 2]\n",
        "\n",
        "  if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nswitch_l = {switch_l}\")\n",
        "  return switch_l\n",
        "\n",
        "switch_letter(\"Mrinmoy Bera\", True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUYx3m9mljwp",
        "outputId": "582277c8-5bd3-4c24-ef15-17b3b72a6c41"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input word = Mrinmoy Bera \n",
            "split_l = [('', 'Mrinmoy Bera'), ('M', 'rinmoy Bera'), ('Mr', 'inmoy Bera'), ('Mri', 'nmoy Bera'), ('Mrin', 'moy Bera'), ('Mrinm', 'oy Bera'), ('Mrinmo', 'y Bera'), ('Mrinmoy', ' Bera'), ('Mrinmoy ', 'Bera'), ('Mrinmoy B', 'era'), ('Mrinmoy Be', 'ra'), ('Mrinmoy Ber', 'a')] \n",
            "switch_l = ['rMinmoy Bera', 'Mirnmoy Bera', 'Mrnimoy Bera', 'Mrimnoy Bera', 'Mrinomy Bera', 'Mrinmyo Bera', 'Mrinmo yBera', 'MrinmoyB era', 'Mrinmoy eBra', 'Mrinmoy Brea', 'Mrinmoy Bear']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rMinmoy Bera',\n",
              " 'Mirnmoy Bera',\n",
              " 'Mrnimoy Bera',\n",
              " 'Mrimnoy Bera',\n",
              " 'Mrinomy Bera',\n",
              " 'Mrinmyo Bera',\n",
              " 'Mrinmo yBera',\n",
              " 'MrinmoyB era',\n",
              " 'Mrinmoy eBra',\n",
              " 'Mrinmoy Brea',\n",
              " 'Mrinmoy Bear']"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os import replace\n",
        "#Replace letter\n",
        "def replace_letter(word, verbose = False) :\n",
        "  letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "  replace_l = []\n",
        "  split_l = []\n",
        "  for c in range(len(word)) :\n",
        "    split_l.append((word[:c], word[c:]))\n",
        "  replace_l = [a + l + (b[1:] if len(b)> 1 else '') for a,b in split_l if b for l in letters]\n",
        "  replace_set=set(replace_l)\n",
        "  replace_set.remove(word)\n",
        "\n",
        "\n",
        " # turn the set back into a list and sort it, for easier viewing\n",
        "  replace_l = sorted(list(replace_set))\n",
        "  if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nreplace_l {replace_l}\")\n",
        "  return replace_l"
      ],
      "metadata": {
        "id": "W76qcfwZCjTp"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replace_letter(\"cat\", True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnfLEiPmHQJ9",
        "outputId": "16d26595-5e2c-424c-dc27-f8416260ee84"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input word = cat \n",
            "split_l = [('', 'cat'), ('c', 'at'), ('ca', 't')] \n",
            "replace_l ['aat', 'bat', 'caa', 'cab', 'cac', 'cad', 'cae', 'caf', 'cag', 'cah', 'cai', 'caj', 'cak', 'cal', 'cam', 'can', 'cao', 'cap', 'caq', 'car', 'cas', 'cau', 'cav', 'caw', 'cax', 'cay', 'caz', 'cbt', 'cct', 'cdt', 'cet', 'cft', 'cgt', 'cht', 'cit', 'cjt', 'ckt', 'clt', 'cmt', 'cnt', 'cot', 'cpt', 'cqt', 'crt', 'cst', 'ctt', 'cut', 'cvt', 'cwt', 'cxt', 'cyt', 'czt', 'dat', 'eat', 'fat', 'gat', 'hat', 'iat', 'jat', 'kat', 'lat', 'mat', 'nat', 'oat', 'pat', 'qat', 'rat', 'sat', 'tat', 'uat', 'vat', 'wat', 'xat', 'yat', 'zat']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['aat',\n",
              " 'bat',\n",
              " 'caa',\n",
              " 'cab',\n",
              " 'cac',\n",
              " 'cad',\n",
              " 'cae',\n",
              " 'caf',\n",
              " 'cag',\n",
              " 'cah',\n",
              " 'cai',\n",
              " 'caj',\n",
              " 'cak',\n",
              " 'cal',\n",
              " 'cam',\n",
              " 'can',\n",
              " 'cao',\n",
              " 'cap',\n",
              " 'caq',\n",
              " 'car',\n",
              " 'cas',\n",
              " 'cau',\n",
              " 'cav',\n",
              " 'caw',\n",
              " 'cax',\n",
              " 'cay',\n",
              " 'caz',\n",
              " 'cbt',\n",
              " 'cct',\n",
              " 'cdt',\n",
              " 'cet',\n",
              " 'cft',\n",
              " 'cgt',\n",
              " 'cht',\n",
              " 'cit',\n",
              " 'cjt',\n",
              " 'ckt',\n",
              " 'clt',\n",
              " 'cmt',\n",
              " 'cnt',\n",
              " 'cot',\n",
              " 'cpt',\n",
              " 'cqt',\n",
              " 'crt',\n",
              " 'cst',\n",
              " 'ctt',\n",
              " 'cut',\n",
              " 'cvt',\n",
              " 'cwt',\n",
              " 'cxt',\n",
              " 'cyt',\n",
              " 'czt',\n",
              " 'dat',\n",
              " 'eat',\n",
              " 'fat',\n",
              " 'gat',\n",
              " 'hat',\n",
              " 'iat',\n",
              " 'jat',\n",
              " 'kat',\n",
              " 'lat',\n",
              " 'mat',\n",
              " 'nat',\n",
              " 'oat',\n",
              " 'pat',\n",
              " 'qat',\n",
              " 'rat',\n",
              " 'sat',\n",
              " 'tat',\n",
              " 'uat',\n",
              " 'vat',\n",
              " 'wat',\n",
              " 'xat',\n",
              " 'yat',\n",
              " 'zat']"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Instructions for insert_letter(): Now implement a function that takes in a word and returns a list with a letter inserted at every offset.\n",
        "def insert_letter(word, verbose = False) :\n",
        "  split_l = []\n",
        "  insert_l = []\n",
        "  letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "  for c in range(len(word)+1) :\n",
        "    split_l.append((word[:c],word[c:]))\n",
        "  insert_l = [a+l+b for a,b in split_l for l in letters]\n",
        "  if verbose: print(f\"Input word {word} \\nsplit_l = {split_l} \\ninsert_l = {insert_l}\")\n",
        "  return insert_l\n",
        "\n",
        "insert_letter(\"cat\",True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwYNXn4kMZtW",
        "outputId": "d9820379-6234-484b-ae69-db77d0b32b14"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input word cat \n",
            "split_l = [('', 'cat'), ('c', 'at'), ('ca', 't'), ('cat', '')] \n",
            "insert_l = ['acat', 'bcat', 'ccat', 'dcat', 'ecat', 'fcat', 'gcat', 'hcat', 'icat', 'jcat', 'kcat', 'lcat', 'mcat', 'ncat', 'ocat', 'pcat', 'qcat', 'rcat', 'scat', 'tcat', 'ucat', 'vcat', 'wcat', 'xcat', 'ycat', 'zcat', 'caat', 'cbat', 'ccat', 'cdat', 'ceat', 'cfat', 'cgat', 'chat', 'ciat', 'cjat', 'ckat', 'clat', 'cmat', 'cnat', 'coat', 'cpat', 'cqat', 'crat', 'csat', 'ctat', 'cuat', 'cvat', 'cwat', 'cxat', 'cyat', 'czat', 'caat', 'cabt', 'cact', 'cadt', 'caet', 'caft', 'cagt', 'caht', 'cait', 'cajt', 'cakt', 'calt', 'camt', 'cant', 'caot', 'capt', 'caqt', 'cart', 'cast', 'catt', 'caut', 'cavt', 'cawt', 'caxt', 'cayt', 'cazt', 'cata', 'catb', 'catc', 'catd', 'cate', 'catf', 'catg', 'cath', 'cati', 'catj', 'catk', 'catl', 'catm', 'catn', 'cato', 'catp', 'catq', 'catr', 'cats', 'catt', 'catu', 'catv', 'catw', 'catx', 'caty', 'catz']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['acat',\n",
              " 'bcat',\n",
              " 'ccat',\n",
              " 'dcat',\n",
              " 'ecat',\n",
              " 'fcat',\n",
              " 'gcat',\n",
              " 'hcat',\n",
              " 'icat',\n",
              " 'jcat',\n",
              " 'kcat',\n",
              " 'lcat',\n",
              " 'mcat',\n",
              " 'ncat',\n",
              " 'ocat',\n",
              " 'pcat',\n",
              " 'qcat',\n",
              " 'rcat',\n",
              " 'scat',\n",
              " 'tcat',\n",
              " 'ucat',\n",
              " 'vcat',\n",
              " 'wcat',\n",
              " 'xcat',\n",
              " 'ycat',\n",
              " 'zcat',\n",
              " 'caat',\n",
              " 'cbat',\n",
              " 'ccat',\n",
              " 'cdat',\n",
              " 'ceat',\n",
              " 'cfat',\n",
              " 'cgat',\n",
              " 'chat',\n",
              " 'ciat',\n",
              " 'cjat',\n",
              " 'ckat',\n",
              " 'clat',\n",
              " 'cmat',\n",
              " 'cnat',\n",
              " 'coat',\n",
              " 'cpat',\n",
              " 'cqat',\n",
              " 'crat',\n",
              " 'csat',\n",
              " 'ctat',\n",
              " 'cuat',\n",
              " 'cvat',\n",
              " 'cwat',\n",
              " 'cxat',\n",
              " 'cyat',\n",
              " 'czat',\n",
              " 'caat',\n",
              " 'cabt',\n",
              " 'cact',\n",
              " 'cadt',\n",
              " 'caet',\n",
              " 'caft',\n",
              " 'cagt',\n",
              " 'caht',\n",
              " 'cait',\n",
              " 'cajt',\n",
              " 'cakt',\n",
              " 'calt',\n",
              " 'camt',\n",
              " 'cant',\n",
              " 'caot',\n",
              " 'capt',\n",
              " 'caqt',\n",
              " 'cart',\n",
              " 'cast',\n",
              " 'catt',\n",
              " 'caut',\n",
              " 'cavt',\n",
              " 'cawt',\n",
              " 'caxt',\n",
              " 'cayt',\n",
              " 'cazt',\n",
              " 'cata',\n",
              " 'catb',\n",
              " 'catc',\n",
              " 'catd',\n",
              " 'cate',\n",
              " 'catf',\n",
              " 'catg',\n",
              " 'cath',\n",
              " 'cati',\n",
              " 'catj',\n",
              " 'catk',\n",
              " 'catl',\n",
              " 'catm',\n",
              " 'catn',\n",
              " 'cato',\n",
              " 'catp',\n",
              " 'catq',\n",
              " 'catr',\n",
              " 'cats',\n",
              " 'catt',\n",
              " 'catu',\n",
              " 'catv',\n",
              " 'catw',\n",
              " 'catx',\n",
              " 'caty',\n",
              " 'catz']"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#edit_one_letter\n",
        "def edit_one_letter(word, allow_switches = True):\n",
        "    edit_one_set = set()\n",
        "    edit_one_set.update(delete_letter(word))\n",
        "    if allow_switches:\n",
        "        edit_one_set.update(switch_letter(word))\n",
        "    edit_one_set.update(replace_letter(word))\n",
        "    edit_one_set.update(insert_letter(word))\n",
        "    return edit_one_set"
      ],
      "metadata": {
        "id": "_vF42LVYQ7VY"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_word = \"at\"\n",
        "tmp_edit_one_set = edit_one_letter(tmp_word)\n",
        "# turn this into a list to sort it, in order to view it\n",
        "tmp_edit_one_l = sorted(list(tmp_edit_one_set))\n",
        "\n",
        "print(f\"input word {tmp_word} \\nedit_one_l \\n{tmp_edit_one_l}\\n\")\n",
        "print(f\"The type of the returned object should be a set {type(tmp_edit_one_set)}\")\n",
        "print(f\"Number of outputs from edit_one_letter('at') is {len(edit_one_letter('at'))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ed3J1q3uT2uN",
        "outputId": "2cf384d5-ed88-40c4-8dfc-a387fe9517fa"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input word at \n",
            "edit_one_l \n",
            "['a', 'aa', 'aat', 'ab', 'abt', 'ac', 'act', 'ad', 'adt', 'ae', 'aet', 'af', 'aft', 'ag', 'agt', 'ah', 'aht', 'ai', 'ait', 'aj', 'ajt', 'ak', 'akt', 'al', 'alt', 'am', 'amt', 'an', 'ant', 'ao', 'aot', 'ap', 'apt', 'aq', 'aqt', 'ar', 'art', 'as', 'ast', 'ata', 'atb', 'atc', 'atd', 'ate', 'atf', 'atg', 'ath', 'ati', 'atj', 'atk', 'atl', 'atm', 'atn', 'ato', 'atp', 'atq', 'atr', 'ats', 'att', 'atu', 'atv', 'atw', 'atx', 'aty', 'atz', 'au', 'aut', 'av', 'avt', 'aw', 'awt', 'ax', 'axt', 'ay', 'ayt', 'az', 'azt', 'bat', 'bt', 'cat', 'ct', 'dat', 'dt', 'eat', 'et', 'fat', 'ft', 'gat', 'gt', 'hat', 'ht', 'iat', 'it', 'jat', 'jt', 'kat', 'kt', 'lat', 'lt', 'mat', 'mt', 'nat', 'nt', 'oat', 'ot', 'pat', 'pt', 'qat', 'qt', 'rat', 'rt', 'sat', 'st', 't', 'ta', 'tat', 'tt', 'uat', 'ut', 'vat', 'vt', 'wat', 'wt', 'xat', 'xt', 'yat', 'yt', 'zat', 'zt']\n",
            "\n",
            "The type of the returned object should be a set <class 'set'>\n",
            "Number of outputs from edit_one_letter('at') is 129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#edit_two_letters\n",
        "def edit_two_letters(word, allow_switches = True):\n",
        "   edit_two_set = set()\n",
        "   edit_one = edit_one_letter(word,allow_switches=allow_switches)\n",
        "   for w in edit_one:\n",
        "      if w:\n",
        "          edit_two = edit_one_letter(w,allow_switches=allow_switches)\n",
        "          edit_two_set.update(edit_two)\n",
        "   return edit_two_set"
      ],
      "metadata": {
        "id": "dTKcI_IjUIFo"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_edit_two_set = edit_two_letters(\"a\")\n",
        "tmp_edit_two_l = sorted(list(tmp_edit_two_set))\n",
        "print(f\"Number of strings with edit distance of two: {len(tmp_edit_two_l)}\")\n",
        "print(f\"First 10 strings {tmp_edit_two_l[:10]}\")\n",
        "print(f\"Last 10 strings {tmp_edit_two_l[-10:]}\")\n",
        "print(f\"The data type of the returned object should be a set {type(tmp_edit_two_set)}\")\n",
        "print(f\"Number of strings that are 2 edit distances from 'at' is {len(edit_two_letters('at'))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sw6iv-OVXic",
        "outputId": "d6643da2-71f2-4213-d310-b1a745f9ac2f"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of strings with edit distance of two: 2654\n",
            "First 10 strings ['', 'a', 'aa', 'aaa', 'aab', 'aac', 'aad', 'aae', 'aaf', 'aag']\n",
            "Last 10 strings ['zv', 'zva', 'zw', 'zwa', 'zx', 'zxa', 'zy', 'zya', 'zz', 'zza']\n",
            "The data type of the returned object should be a set <class 'set'>\n",
            "Number of strings that are 2 edit distances from 'at' is 7154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_corrections(word, probs, vocab, n=2, verbose = False):\n",
        "    suggestions = []\n",
        "    n_best = []\n",
        "    if (word in vocab) :\n",
        "      suggestions.append(word)\n",
        "    else :\n",
        "      suggestions =list(edit_one_letter(word).intersection(vocab) or edit_two_letters(word).intersection(vocab))\n",
        "    n_best = [[s,probs[s]] for s in list(reversed(suggestions))]\n",
        "    if verbose: print(\"suggestions = \", suggestions)\n",
        "\n",
        "    return n_best"
      ],
      "metadata": {
        "id": "pkmXFlGPWLst"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = get_corrections('so', word_prob_dict, vocab, 2, verbose=False)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5tJhE6cgR4h",
        "outputId": "b27349e4-6d1f-4299-d900-d919603ca263"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['so', 0.006565449322938038]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your implementation - feel free to try other words in my word\n",
        "my_word = 'so'\n",
        "tmp_corrections = get_corrections(my_word, word_prob_dict, vocab, 2, verbose=False)\n",
        "for i, word_prob in enumerate(tmp_corrections):\n",
        "    print(f\"word {i}: {word_prob[0]}, probability {word_prob[1]:.6f}\")\n",
        "# CODE REVIEW COMMENT: using \"tmp_corrections\" insteads of \"cors\". \"cors\" is not defined\n",
        "print(f\"data type of corrections {type(tmp_corrections)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SA2IfsmxYGW3",
        "outputId": "68fc8b0a-1a90-4cd7-9148-3a5fd09680c9"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word 0: so, probability 0.006565\n",
            "data type of corrections <class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(reversed(['do','is','du', 's'])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfeiYP2YZ4CQ",
        "outputId": "1083ca21-5f08-4e8e-f718-8ba04f2c9ea6"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['s', 'du', 'is', 'do']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def min_edit_distance(source, target, ins_cost = 1, del_cost = 1, rep_cost = 2):\n",
        "    '''\n",
        "    Input:\n",
        "        source: a string corresponding to the string you are starting with\n",
        "        target: a string corresponding to the string you want to end with\n",
        "        ins_cost: an integer setting the insert cost\n",
        "        del_cost: an integer setting the delete cost\n",
        "        rep_cost: an integer setting the replace cost\n",
        "    Output:\n",
        "        D: a matrix of len(source)+1 by len(target)+1 containing minimum edit distances\n",
        "        med: the minimum edit distance (med) required to convert the source string to the target\n",
        "    '''\n",
        "    # use deletion and insert cost as  1\n",
        "    m = len(source)\n",
        "    n = len(target)\n",
        "\n",
        "    #initialize cost matrix with zeros and dimensions (m+1,n+1)\n",
        "    D = np.zeros((m+1, n+1), dtype=int)\n",
        "\n",
        "    ### START CODE HERE (Replace instances of 'None' with your code) ###\n",
        "    # Fill in column 0, from row 1 to row m\n",
        "    for row in range(1,m+1): # Replace None with the proper range\n",
        "        D[row,0] = D[row-1,0] + del_cost\n",
        "\n",
        "    # Fill in row 0, for all columns from 1 to n\n",
        "    for col in range(1,n+1): # Replace None with the proper range\n",
        "        D[0,col] = D[0,col-1] + ins_cost\n",
        "\n",
        "    # Loop through row 1 to row m\n",
        "    for row in range(1,m+1):\n",
        "\n",
        "        # Loop through column 1 to column n\n",
        "        for col in range(1,n+1):\n",
        "\n",
        "            # Intialize r_cost to the 'replace' cost that is passed into this function\n",
        "            r_cost = rep_cost\n",
        "\n",
        "            # Check to see if source character at the previous row\n",
        "            # matches the target character at the previous column,\n",
        "            if source[row-1] == target[col-1]:\n",
        "                # Update the replacement cost to 0 if source and target are the same\n",
        "                r_cost = 0\n",
        "\n",
        "            # Update the cost at row, col based on previous entries in the cost matrix\n",
        "            # Refer to the equation calculate for D[i,j] (the minimum of three calculated costs)\n",
        "            D[row,col] = min([D[row-1,col]+del_cost, D[row,col-1]+ins_cost, D[row-1,col-1]+r_cost])\n",
        "\n",
        "    # Set the minimum edit distance with the cost found at row m, column n\n",
        "    med = D[m,n]\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "    return D, med"
      ],
      "metadata": {
        "id": "2wv2qnQsA7fP"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source =  'play'\n",
        "target = 'stay'\n",
        "matrix, min_edits = min_edit_distance(source, target)\n",
        "print(\"minimum edits: \",min_edits, \"\\n\")\n",
        "idx = list('#' + source)\n",
        "cols = list('#' + target)\n",
        "df = pd.DataFrame(matrix, index=idx, columns= cols)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeukZZ3LA847",
        "outputId": "337633e4-2f4a-428a-d493-80a5f55e0ff3"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "minimum edits:  4 \n",
            "\n",
            "   #  s  t  a  y\n",
            "#  0  1  2  3  4\n",
            "p  1  2  3  4  5\n",
            "l  2  3  4  5  6\n",
            "a  3  4  5  4  5\n",
            "y  4  5  6  5  4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "source =  'eer'\n",
        "target = 'near'\n",
        "matrix, min_edits = min_edit_distance(source, target)\n",
        "print(\"minimum edits: \",min_edits, \"\\n\")\n",
        "idx = list(source)\n",
        "idx.insert(0, '#')\n",
        "cols = list(target)\n",
        "cols.insert(0, '#')\n",
        "df = pd.DataFrame(matrix, index=idx, columns= cols)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OAYwoiHBGxy",
        "outputId": "d652cc0b-bf1a-4efa-847a-166a00846d1a"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "minimum edits:  3 \n",
            "\n",
            "   #  n  e  a  r\n",
            "#  0  1  2  3  4\n",
            "e  1  2  1  2  3\n",
            "e  2  3  2  3  4\n",
            "r  3  4  3  4  3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Autocorrect model"
      ],
      "metadata": {
        "id": "myywLXvzlx83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def autocorrect(input_word,  word_prob_dict, vocab, verbose=False) :\n",
        "  tmp_corrections = get_corrections(input_word, word_prob_dict, vocab, 2, verbose=False)\n",
        "  edit_distances = []\n",
        "  for i, word_prob in enumerate(tmp_corrections):\n",
        "    matrix, min_edits = min_edit_distance(input_word, word_prob[0])\n",
        "    edit_distances.append(min_edits)\n",
        "  index_of_min_edit_dis = np.argmin(edit_distances)\n",
        "  predict_word = tmp_corrections[index_of_min_edit_dis][0]\n",
        "  return predict_word\n"
      ],
      "metadata": {
        "id": "pDdbsy8pBr_q"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Demo of our model"
      ],
      "metadata": {
        "id": "BVOVHfyMlnBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_word = 'dys'\n",
        "autocorrect(input_word,  word_prob_dict, vocab, verbose=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "96R_0PxLU7OM",
        "outputId": "81aac2f4-b7f2-4da7-a520-a7d40088ba57"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'days'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_word = 'deat'\n",
        "autocorrect(input_word,  word_prob_dict, vocab, verbose=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "XjhIyVM1lFOF",
        "outputId": "381ecc70-47e9-4480-f7f1-ca47e8af3458"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'death'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_word = 'dera'\n",
        "autocorrect(input_word,  word_prob_dict, vocab, verbose=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0edKxrAilOlX",
        "outputId": "a157ef85-533f-4d72-c52e-08b6054aa213"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dear'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_word = 'asssume'\n",
        "autocorrect(input_word,  word_prob_dict, vocab, verbose=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Gdi7iB5flTes",
        "outputId": "b42238dc-6f4f-4e49-9568-05ad214997a3"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'assume'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_word = 'asum'\n",
        "autocorrect(input_word,  word_prob_dict, vocab, verbose=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ozeMJrhrlgN-",
        "outputId": "718dd746-e3c6-412a-d184-6128930588c9"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sum'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    }
  ]
}